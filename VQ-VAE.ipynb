{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages (from pydot) (3.0.9)\n",
      "Requirement already satisfied: graphviz in c:\\users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages (0.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "import pathlib\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU,Add\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "batch_size =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_img(img):\n",
    "  # Convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  # Resize the image to the desired size\n",
    "  return tf.image.resize(img, [img_height, img_width])\n",
    "\n",
    "\n",
    "def process_path(file_path):\n",
    "\n",
    "  # Load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img,\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files('data_dir''*/*', shuffle=False)\n",
    "val_size = int(tf.data.experimental.cardinality(list_ds).numpy() * 0.3)\n",
    "\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)\n",
    "\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(layers.Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "\n",
    "        # The `beta` parameter is best kept between [0.25, 2] as per the paper.\n",
    "        self.beta = beta\n",
    "\n",
    "        # Initialize the embeddings which we will quantize. This means give me an embedding codebook with \n",
    "        # num_embedding codes each of embedding_dim dimensions. for instance for the default paramenters \n",
    "        # num_embeddings = 64 and embedding_dims = 16 this will give me a (16,64) matrix 64 vectors of dim 16\n",
    "        w_init = tf.random_uniform_initializer()\n",
    "        self.embeddings = tf.Variable(\n",
    "            initial_value=w_init(\n",
    "                shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "            name=\"embeddings_vqvae\",\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        # Calculate the input shape of the inputs and\n",
    "        # then flatten the inputs keeping `embedding_dim` intact.\n",
    "        input_shape = tf.shape(x)\n",
    "        flattened = tf.reshape(x, [-1, self.embedding_dim])\n",
    "        \n",
    "        \n",
    "\n",
    "        # Quantization.\n",
    "        \n",
    "        # Get the index of the closest codebook vector for each of the HxW codebook vectors\n",
    "        encoding_indices = self.get_code_indices(flattened)  \n",
    "        \n",
    "        # Encode in a onehot matrix and retrieve the corresponding codebook with a matrix multiplicatino\n",
    "        encodings = tf.one_hot(encoding_indices, self.num_embeddings)   \n",
    "        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
    "\n",
    "        # Reshape the quantized values back to the original input shape\n",
    "        # I think this could just be a transpose operation\n",
    "        quantized = tf.reshape(quantized, input_shape)\n",
    "\n",
    "        # Calculate vector quantization loss and add that to the layer. You can learn more\n",
    "        # about adding losses to different layers here:\n",
    "        # https://keras.io/guides/making_new_layers_and_models_via_subclassing/. Check\n",
    "        # the original paper to get a handle on the formulation of the loss function.\n",
    "        commitment_loss = tf.reduce_mean((tf.stop_gradient(quantized) - x) ** 2)\n",
    "        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n",
    "        self.add_loss(self.beta * commitment_loss + codebook_loss)\n",
    "\n",
    "        # Straight-through estimator.\n",
    "        quantized = x + tf.stop_gradient(quantized - x)\n",
    "        return quantized\n",
    "\n",
    "    def get_code_indices(self, flattened_inputs):\n",
    "        # Calculate L2-normalized distance between the inputs and the codes.\n",
    "        # Similarity is a matrix that compares ALL the encoder codes with all the embedding codes. \n",
    "        # Thus the shape becomes \n",
    "        # (#HxW,EmbeddingDimensionaltiy) x (#EmbeddingDimensionaltiy,#NumCodebookVecs) : (#HxW,NumCodebookVecs)\n",
    "        # (#HxW,16) x (16,64) : (#HxW,64)\n",
    "        \n",
    "        similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
    "        \n",
    "        # Distances outputs  (#HXW,64)\n",
    "        distances = (\n",
    "            tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n",
    "            + tf.reduce_sum(self.embeddings ** 2, axis=0)\n",
    "            - 2 * similarity\n",
    "        )\n",
    "\n",
    "        # Derive the indices for minimum distances.\n",
    "        # For each of the #HXW code this next line selects the 1-out-of-64 minimum distance\n",
    "        encoding_indices = tf.argmin(distances, axis=1)\n",
    "        return encoding_indices\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Dimentionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16             # The number \n",
    "num_embeddings = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the components\n",
    "\n",
    "encoder = get_encoder(num_embeddings)\n",
    "vq_layer = VectorQuantizer(num_embeddings, embedding_dim, name=\"vector_quantizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = keras.Input(shape=(7, 7, embedding_dim))\n",
    "quantized_latents = vq_layer(encoder_outputs)\n",
    "qunatitized = keras.Model(encoder_outputs, quantized_latents, name=\"vq_vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = tf.shape(encoder_outputs)\n",
    "flattened = tf.reshape(encoder_outputs, [-1,embedding_dim])\n",
    "\n",
    "print(flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 64)\n"
     ]
    }
   ],
   "source": [
    "w_init = tf.random_uniform_initializer()\n",
    "embeddings = tf.Variable(\n",
    "            initial_value=w_init(shape=(embedding_dim, num_embeddings), dtype=\"float32\"),  \n",
    "            trainable=True,\n",
    "            name=\"embeddings_vqvae\",\n",
    "        )\n",
    "print(embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul), but are not present in its tracked objects:   <tf.Variable 'embeddings_vqvae:0' shape=(16, 64) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "similarity = tf.matmul(flattened, embeddings)\n",
    "print(similarity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "distances = (\n",
    "    tf.reduce_sum(flattened ** 2, axis=1, keepdims=True)\n",
    "    + tf.reduce_sum(embeddings ** 2, axis=0)\n",
    "    - 2 * similarity\n",
    ")\n",
    "\n",
    "print(distances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None,)\n"
     ]
    }
   ],
   "source": [
    "encoding_indices = tf.argmin(distances, axis=1)\n",
    "\n",
    "print(encoding_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened.shape         # In this case a Vector of BHWC of Batchx7x7x16 will be flatten to 49x16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the VQ-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32              # The number \n",
    "num_embeddings = 512            # The number of vectors in the codebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_encoder(input_shape, num_filters, latent_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(num_filters, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    # downsample via strided convolutions\n",
    "    filters = [num_filters, num_filters*2, num_filters*4, num_filters*8]\n",
    "    size = len(filters)\n",
    "    for i in range(size):\n",
    "        for j in range(2):\n",
    "            # first block of each layer uses stride 2\n",
    "            strides = 2 if j == 0 else 1\n",
    "            x = resnet_block(x, filters[i], strides=strides)\n",
    "\n",
    "    # final conv layer\n",
    "    x = Conv2D(latent_dim, kernel_size=1, strides=1)(x)\n",
    "\n",
    "    model = Model(inputs, x,name='Encoder')\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_block(inputs, filters, strides=1):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n",
    "\n",
    "    shortcut = inputs\n",
    "    if strides != 1 or inputs.shape[3] != filters:\n",
    "        shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='valid')(inputs)\n",
    "\n",
    "    x = Add()([x, shortcut])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_176 (Conv2D)            (None, 128, 128, 64  9472        ['input_19[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 128, 128, 64  256        ['conv2d_176[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_136 (LeakyReLU)    (None, 128, 128, 64  0           ['batch_normalization_160[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 128, 128, 64  256        ['leaky_re_lu_136[0][0]']        \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_137 (LeakyReLU)    (None, 128, 128, 64  0           ['batch_normalization_161[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_177 (Conv2D)            (None, 64, 64, 64)   36928       ['leaky_re_lu_137[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 64, 64, 64)  256         ['conv2d_177[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_138 (LeakyReLU)    (None, 64, 64, 64)   0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_178 (Conv2D)            (None, 64, 64, 64)   36928       ['leaky_re_lu_138[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_179 (Conv2D)            (None, 64, 64, 64)   4160        ['leaky_re_lu_136[0][0]']        \n",
      "                                                                                                  \n",
      " add_64 (Add)                   (None, 64, 64, 64)   0           ['conv2d_178[0][0]',             \n",
      "                                                                  'conv2d_179[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 64, 64, 64)  256         ['add_64[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_139 (LeakyReLU)    (None, 64, 64, 64)   0           ['batch_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_180 (Conv2D)            (None, 64, 64, 64)   36928       ['leaky_re_lu_139[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_164 (Batch  (None, 64, 64, 64)  256         ['conv2d_180[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_140 (LeakyReLU)    (None, 64, 64, 64)   0           ['batch_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_181 (Conv2D)            (None, 64, 64, 64)   36928       ['leaky_re_lu_140[0][0]']        \n",
      "                                                                                                  \n",
      " add_65 (Add)                   (None, 64, 64, 64)   0           ['conv2d_181[0][0]',             \n",
      "                                                                  'add_64[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_165 (Batch  (None, 64, 64, 64)  256         ['add_65[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_141 (LeakyReLU)    (None, 64, 64, 64)   0           ['batch_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_182 (Conv2D)            (None, 32, 32, 128)  73856       ['leaky_re_lu_141[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_166 (Batch  (None, 32, 32, 128)  512        ['conv2d_182[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_142 (LeakyReLU)    (None, 32, 32, 128)  0           ['batch_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_183 (Conv2D)            (None, 32, 32, 128)  147584      ['leaky_re_lu_142[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_184 (Conv2D)            (None, 32, 32, 128)  8320        ['add_65[0][0]']                 \n",
      "                                                                                                  \n",
      " add_66 (Add)                   (None, 32, 32, 128)  0           ['conv2d_183[0][0]',             \n",
      "                                                                  'conv2d_184[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_167 (Batch  (None, 32, 32, 128)  512        ['add_66[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_143 (LeakyReLU)    (None, 32, 32, 128)  0           ['batch_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_185 (Conv2D)            (None, 32, 32, 128)  147584      ['leaky_re_lu_143[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_168 (Batch  (None, 32, 32, 128)  512        ['conv2d_185[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_144 (LeakyReLU)    (None, 32, 32, 128)  0           ['batch_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_186 (Conv2D)            (None, 32, 32, 128)  147584      ['leaky_re_lu_144[0][0]']        \n",
      "                                                                                                  \n",
      " add_67 (Add)                   (None, 32, 32, 128)  0           ['conv2d_186[0][0]',             \n",
      "                                                                  'add_66[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_169 (Batch  (None, 32, 32, 128)  512        ['add_67[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_145 (LeakyReLU)    (None, 32, 32, 128)  0           ['batch_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_187 (Conv2D)            (None, 16, 16, 256)  295168      ['leaky_re_lu_145[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_170 (Batch  (None, 16, 16, 256)  1024       ['conv2d_187[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_146 (LeakyReLU)    (None, 16, 16, 256)  0           ['batch_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)            (None, 16, 16, 256)  590080      ['leaky_re_lu_146[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)            (None, 16, 16, 256)  33024       ['add_67[0][0]']                 \n",
      "                                                                                                  \n",
      " add_68 (Add)                   (None, 16, 16, 256)  0           ['conv2d_188[0][0]',             \n",
      "                                                                  'conv2d_189[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_171 (Batch  (None, 16, 16, 256)  1024       ['add_68[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_147 (LeakyReLU)    (None, 16, 16, 256)  0           ['batch_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)            (None, 16, 16, 256)  590080      ['leaky_re_lu_147[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_172 (Batch  (None, 16, 16, 256)  1024       ['conv2d_190[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_148 (LeakyReLU)    (None, 16, 16, 256)  0           ['batch_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)            (None, 16, 16, 256)  590080      ['leaky_re_lu_148[0][0]']        \n",
      "                                                                                                  \n",
      " add_69 (Add)                   (None, 16, 16, 256)  0           ['conv2d_191[0][0]',             \n",
      "                                                                  'add_68[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_173 (Batch  (None, 16, 16, 256)  1024       ['add_69[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_149 (LeakyReLU)    (None, 16, 16, 256)  0           ['batch_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)            (None, 8, 8, 512)    1180160     ['leaky_re_lu_149[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_174 (Batch  (None, 8, 8, 512)   2048        ['conv2d_192[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_150 (LeakyReLU)    (None, 8, 8, 512)    0           ['batch_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)            (None, 8, 8, 512)    2359808     ['leaky_re_lu_150[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)            (None, 8, 8, 512)    131584      ['add_69[0][0]']                 \n",
      "                                                                                                  \n",
      " add_70 (Add)                   (None, 8, 8, 512)    0           ['conv2d_193[0][0]',             \n",
      "                                                                  'conv2d_194[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_175 (Batch  (None, 8, 8, 512)   2048        ['add_70[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_151 (LeakyReLU)    (None, 8, 8, 512)    0           ['batch_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)            (None, 8, 8, 512)    2359808     ['leaky_re_lu_151[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_176 (Batch  (None, 8, 8, 512)   2048        ['conv2d_195[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_152 (LeakyReLU)    (None, 8, 8, 512)    0           ['batch_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)            (None, 8, 8, 512)    2359808     ['leaky_re_lu_152[0][0]']        \n",
      "                                                                                                  \n",
      " add_71 (Add)                   (None, 8, 8, 512)    0           ['conv2d_196[0][0]',             \n",
      "                                                                  'add_70[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)            (None, 8, 8, 32)     16416       ['add_71[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,206,112\n",
      "Trainable params: 11,199,200\n",
      "Non-trainable params: 6,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = resnet_encoder(input_shape=(256, 256, 3), num_filters=64, latent_dim=embedding_dim)\n",
    "encoder_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(encoder_model, to_file='encoder.png', show_shapes=True,show_layer_names=False,dpi=180)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output_shape = encoder_model.layers[-1].output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def dcgenerator(encoder_output_shape):\n",
    "    # Input shape: (8, 8, 256)\n",
    "    inputs = tf.keras.layers.Input(shape=encoder_output_shape)\n",
    "\n",
    "    # Upsample to (16, 16, 128)\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Upsample to (32, 32, 64)\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Upsample to (64, 64, 32)\n",
    "    x = tf.keras.layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Upsample to (128, 128, 16)\n",
    "    x = tf.keras.layers.Conv2DTranspose(16, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Upsample to (256, 256, 3)\n",
    "    outputs = tf.keras.layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh', use_bias=False)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs,name='Decoder')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vqvae(num_embeddings=512,embedding_dim=32):\n",
    "    vq_layer = VectorQuantizer(num_embeddings, embedding_dim, name=\"vector_quantizer\")\n",
    "    encoder = resnet_encoder(input_shape=(256, 256, 3), num_filters=64, latent_dim=embedding_dim)\n",
    "    decoder = dcgenerator(encoder_output_shape)\n",
    "\n",
    "    inputs = keras.Input(shape=(256, 256, 3))\n",
    "    encoder_outputs = encoder(inputs)\n",
    "    quantized_latents = vq_layer(encoder_outputs)\n",
    "    reconstructions = decoder(quantized_latents)\n",
    "    vqvae_model = keras.Model(inputs, reconstructions, name=\"vq_vae\")\n",
    "    \n",
    "    return vqvae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAETrainer(keras.models.Model):\n",
    "    def __init__(self, latent_dim=32, num_embeddings=128, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "\n",
    "        self.vqvae = build_vqvae(embedding_dim=self.latent_dim, num_embeddings=self.num_embeddings)\n",
    "\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.vq_loss_tracker = keras.metrics.Mean(name=\"vq_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.vq_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Outputs from the VQ-VAE.\n",
    "            reconstructions = self.vqvae(x)\n",
    "\n",
    "            # Calculate the losses.\n",
    "            reconstruction_loss = (\n",
    "                tf.reduce_mean((x - reconstructions) ** 2) \n",
    "            )\n",
    "            total_loss = reconstruction_loss + sum(self.vqvae.losses)\n",
    "\n",
    "        # Backpropagation.\n",
    "        grads = tape.gradient(total_loss, self.vqvae.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))\n",
    "\n",
    "        # Loss tracking.\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.vq_loss_tracker.update_state(sum(self.vqvae.losses))\n",
    "\n",
    "        # Log results.\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"vqvae_loss\": self.vq_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_layer = VectorQuantizer(num_embeddings, embedding_dim, name=\"vector_quantizer\")\n",
    "encoder = resnet_encoder(input_shape=(256, 256, 3), num_filters=64, latent_dim=embedding_dim)\n",
    "decoder = dcgenerator(encoder_output_shape)\n",
    "\n",
    "inputs = keras.Input(shape=(256, 256, 3))\n",
    "encoder_outputs = encoder(inputs)\n",
    "quantized_latents = vq_layer(encoder_outputs)\n",
    "reconstructions = decoder(quantized_latents)\n",
    "vqvae_model = keras.Model(inputs, reconstructions, name=\"vq_vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae_trainer = VQVAETrainer(latent_dim=embedding_dim, num_embeddings=num_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 812/1511 [===============>..............] - ETA: 7:31 - loss: 4531413377.4553 - reconstruction_loss: 18609.1211 - vqvae_loss: 4531392892.4017"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\castr\\Documents\\Generative_AI\\VQ-VAE.ipynb Cell 35\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/castr/Documents/Generative_AI/VQ-VAE.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vqvae_trainer\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam())\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/castr/Documents/Generative_AI/VQ-VAE.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m vqvae_trainer\u001b[39m.\u001b[39;49mfit(train_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vqvae_trainer.compile(optimizer=keras.optimizers.Adam())\n",
    "vqvae_trainer.fit(train_ds, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work-portable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

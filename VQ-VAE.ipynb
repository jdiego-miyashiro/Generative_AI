{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages (from pydot) (3.0.9)\n",
      "Requirement already satisfied: graphviz in c:\\users\\castr\\.conda\\envs\\work-portable\\lib\\site-packages (0.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "import pathlib\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU,Add\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "batch_size =18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_img(img):\n",
    "  # Convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  # Resize the image to the desired size\n",
    "  return tf.image.resize(img, [img_height, img_width])\n",
    "\n",
    "\n",
    "def process_path(file_path):\n",
    "\n",
    "  # Load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img,\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files('data_dir''*/*', shuffle=False)\n",
    "val_size = int(tf.data.experimental.cardinality(list_ds).numpy() * 0.3)\n",
    "\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)\n",
    "\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(layers.Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "\n",
    "        # The `beta` parameter is best kept between [0.25, 2] as per the paper.\n",
    "        self.beta = beta\n",
    "\n",
    "        # Initialize the embeddings which we will quantize. This means give me an embedding codebook with \n",
    "        # num_embedding codes each of embedding_dim dimensions. for instance for the default paramenters \n",
    "        # num_embeddings = 64 and embedding_dims = 16 this will give me a (16,64) matrix 64 vectors of dim 16\n",
    "        w_init = tf.random_uniform_initializer()\n",
    "        self.embeddings = tf.Variable(\n",
    "            initial_value=w_init(\n",
    "                shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "            name=\"embeddings_vqvae\",\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        # Calculate the input shape of the inputs and\n",
    "        # then flatten the inputs keeping `embedding_dim` intact.\n",
    "        input_shape = tf.shape(x)\n",
    "        flattened = tf.reshape(x, [-1, self.embedding_dim])\n",
    "        \n",
    "        \n",
    "\n",
    "        # Quantization.\n",
    "        \n",
    "        # Get the index of the closest codebook vector for each of the HxW codebook vectors\n",
    "        encoding_indices = self.get_code_indices(flattened)  \n",
    "        \n",
    "        # Encode in a onehot matrix and retrieve the corresponding codebook with a matrix multiplicatino\n",
    "        encodings = tf.one_hot(encoding_indices, self.num_embeddings)   \n",
    "        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
    "\n",
    "        # Reshape the quantized values back to the original input shape\n",
    "        # I think this could just be a transpose operation\n",
    "        quantized = tf.reshape(quantized, input_shape)\n",
    "\n",
    "        # Calculate vector quantization loss and add that to the layer. You can learn more\n",
    "        # about adding losses to different layers here:\n",
    "        # https://keras.io/guides/making_new_layers_and_models_via_subclassing/. Check\n",
    "        # the original paper to get a handle on the formulation of the loss function.\n",
    "        commitment_loss = tf.reduce_mean((tf.stop_gradient(quantized) - x) ** 2)\n",
    "        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n",
    "        self.add_loss(self.beta * commitment_loss + codebook_loss)\n",
    "\n",
    "        # Straight-through estimator.\n",
    "        quantized = x + tf.stop_gradient(quantized - x)\n",
    "        return quantized\n",
    "\n",
    "    def get_code_indices(self, flattened_inputs):\n",
    "        # Calculate L2-normalized distance between the inputs and the codes.\n",
    "        # Similarity is a matrix that compares ALL the encoder codes with all the embedding codes. \n",
    "        # Thus the shape becomes \n",
    "        # (#HxW,EmbeddingDimensionaltiy) x (#EmbeddingDimensionaltiy,#NumCodebookVecs) : (#HxW,NumCodebookVecs)\n",
    "        # (#HxW,16) x (16,64) : (#HxW,64)\n",
    "        \n",
    "        similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
    "        \n",
    "        # Distances outputs  (#HXW,64)\n",
    "        distances = (\n",
    "            tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n",
    "            + tf.reduce_sum(self.embeddings ** 2, axis=0)\n",
    "            - 2 * similarity\n",
    "        )\n",
    "\n",
    "        # Derive the indices for minimum distances.\n",
    "        # For each of the #HXW code this next line selects the 1-out-of-64 minimum distance\n",
    "        encoding_indices = tf.argmin(distances, axis=1)\n",
    "        return encoding_indices\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Dimentionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16             # The number \n",
    "num_embeddings = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the components\n",
    "\n",
    "encoder = get_encoder(num_embeddings)\n",
    "vq_layer = VectorQuantizer(num_embeddings, embedding_dim, name=\"vector_quantizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = keras.Input(shape=(7, 7, embedding_dim))\n",
    "quantized_latents = vq_layer(encoder_outputs)\n",
    "qunatitized = keras.Model(encoder_outputs, quantized_latents, name=\"vq_vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = tf.shape(encoder_outputs)\n",
    "flattened = tf.reshape(encoder_outputs, [-1,embedding_dim])\n",
    "\n",
    "print(flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 64)\n"
     ]
    }
   ],
   "source": [
    "w_init = tf.random_uniform_initializer()\n",
    "embeddings = tf.Variable(\n",
    "            initial_value=w_init(shape=(embedding_dim, num_embeddings), dtype=\"float32\"),  \n",
    "            trainable=True,\n",
    "            name=\"embeddings_vqvae\",\n",
    "        )\n",
    "print(embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul), but are not present in its tracked objects:   <tf.Variable 'embeddings_vqvae:0' shape=(16, 64) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "similarity = tf.matmul(flattened, embeddings)\n",
    "print(similarity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "distances = (\n",
    "    tf.reduce_sum(flattened ** 2, axis=1, keepdims=True)\n",
    "    + tf.reduce_sum(embeddings ** 2, axis=0)\n",
    "    - 2 * similarity\n",
    ")\n",
    "\n",
    "print(distances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None,)\n"
     ]
    }
   ],
   "source": [
    "encoding_indices = tf.argmin(distances, axis=1)\n",
    "\n",
    "print(encoding_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened.shape         # In this case a Vector of BHWC of Batchx7x7x16 will be flatten to 49x16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the VQ-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32              # The number \n",
    "num_embeddings = 512            # The number of vectors in the codebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_encoder(input_shape, num_filters, latent_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(num_filters, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    # downsample via strided convolutions\n",
    "    filters = [num_filters, num_filters*2, num_filters*4, num_filters*8]\n",
    "    size = len(filters)\n",
    "    for i in range(size):\n",
    "        for j in range(2):\n",
    "            # first block of each layer uses stride 2\n",
    "            strides = 2 if j == 0 else 1\n",
    "            x = resnet_block(x, filters[i], strides=strides)\n",
    "\n",
    "    # final conv layer\n",
    "    x = Conv2D(latent_dim, kernel_size=1, strides=1)(x)\n",
    "\n",
    "    model = Model(inputs, x,name='Encoder')\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_block(inputs, filters, strides=1):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n",
    "\n",
    "    shortcut = inputs\n",
    "    if strides != 1 or inputs.shape[3] != filters:\n",
    "        shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='valid')(inputs)\n",
    "\n",
    "    x = Add()([x, shortcut])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 128, 128, 64  9472        ['input_11[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 128, 128, 64  256        ['conv2d_110[0][0]']             \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_85 (LeakyReLU)     (None, 128, 128, 64  0           ['batch_normalization_97[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 128, 128, 64  256        ['leaky_re_lu_85[0][0]']         \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_86 (LeakyReLU)     (None, 128, 128, 64  0           ['batch_normalization_98[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 64, 64, 64)   36928       ['leaky_re_lu_86[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 64, 64, 64)  256         ['conv2d_111[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_87 (LeakyReLU)     (None, 64, 64, 64)   0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 64, 64, 64)   36928       ['leaky_re_lu_87[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 64, 64, 64)   4160        ['leaky_re_lu_85[0][0]']         \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 64, 64, 64)   0           ['conv2d_112[0][0]',             \n",
      "                                                                  'conv2d_113[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 64, 64, 64)  256         ['add_40[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_88 (LeakyReLU)     (None, 64, 64, 64)   0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 64, 64, 64)   36928       ['leaky_re_lu_88[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 64, 64, 64)  256         ['conv2d_114[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_89 (LeakyReLU)     (None, 64, 64, 64)   0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 64, 64, 64)   36928       ['leaky_re_lu_89[0][0]']         \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 64, 64, 64)   0           ['conv2d_115[0][0]',             \n",
      "                                                                  'add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 64, 64, 64)  256         ['add_41[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_90 (LeakyReLU)     (None, 64, 64, 64)   0           ['batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 32, 32, 128)  73856       ['leaky_re_lu_90[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 32, 32, 128)  512        ['conv2d_116[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_91 (LeakyReLU)     (None, 32, 32, 128)  0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 32, 32, 128)  147584      ['leaky_re_lu_91[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 32, 32, 128)  8320        ['add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 32, 32, 128)  0           ['conv2d_117[0][0]',             \n",
      "                                                                  'conv2d_118[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 32, 32, 128)  512        ['add_42[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_92 (LeakyReLU)     (None, 32, 32, 128)  0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 32, 32, 128)  147584      ['leaky_re_lu_92[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 32, 32, 128)  512        ['conv2d_119[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_93 (LeakyReLU)     (None, 32, 32, 128)  0           ['batch_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 32, 32, 128)  147584      ['leaky_re_lu_93[0][0]']         \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 32, 32, 128)  0           ['conv2d_120[0][0]',             \n",
      "                                                                  'add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 32, 32, 128)  512        ['add_43[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_94 (LeakyReLU)     (None, 32, 32, 128)  0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 16, 16, 256)  295168      ['leaky_re_lu_94[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 16, 16, 256)  1024       ['conv2d_121[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_95 (LeakyReLU)     (None, 16, 16, 256)  0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 16, 16, 256)  590080      ['leaky_re_lu_95[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 16, 16, 256)  33024       ['add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 16, 16, 256)  0           ['conv2d_122[0][0]',             \n",
      "                                                                  'conv2d_123[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, 16, 16, 256)  1024       ['add_44[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_96 (LeakyReLU)     (None, 16, 16, 256)  0           ['batch_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 16, 16, 256)  590080      ['leaky_re_lu_96[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, 16, 16, 256)  1024       ['conv2d_124[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_97 (LeakyReLU)     (None, 16, 16, 256)  0           ['batch_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 16, 16, 256)  590080      ['leaky_re_lu_97[0][0]']         \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 16, 16, 256)  0           ['conv2d_125[0][0]',             \n",
      "                                                                  'add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, 16, 16, 256)  1024       ['add_45[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_98 (LeakyReLU)     (None, 16, 16, 256)  0           ['batch_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 8, 8, 512)    1180160     ['leaky_re_lu_98[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, 8, 8, 512)   2048        ['conv2d_126[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_99 (LeakyReLU)     (None, 8, 8, 512)    0           ['batch_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 8, 8, 512)    2359808     ['leaky_re_lu_99[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 8, 8, 512)    131584      ['add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 8, 8, 512)    0           ['conv2d_127[0][0]',             \n",
      "                                                                  'conv2d_128[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, 8, 8, 512)   2048        ['add_46[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_100 (LeakyReLU)    (None, 8, 8, 512)    0           ['batch_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 8, 8, 512)    2359808     ['leaky_re_lu_100[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, 8, 8, 512)   2048        ['conv2d_129[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_101 (LeakyReLU)    (None, 8, 8, 512)    0           ['batch_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 8, 8, 512)    2359808     ['leaky_re_lu_101[0][0]']        \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 8, 8, 512)    0           ['conv2d_130[0][0]',             \n",
      "                                                                  'add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 8, 8, 32)     16416       ['add_47[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,206,112\n",
      "Trainable params: 11,199,200\n",
      "Non-trainable params: 6,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = resnet_encoder(input_shape=(256, 256, 3), num_filters=64, latent_dim=embedding_dim)\n",
    "encoder_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(encoder_model, to_file='encoder.png', show_shapes=True,show_layer_names=False,dpi=180)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output_shape = encoder_model.layers[-1].output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def dcgenerator(encoder_output_shape):\n",
    "    # Input shape: (8, 8, 256)\n",
    "    inputs = tf.keras.layers.Input(shape=encoder_output_shape)\n",
    "\n",
    "    # Upsample to (16, 16, 128)\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Upsample to (32, 32, 64)\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Upsample to (64, 64, 32)\n",
    "    x = tf.keras.layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Upsample to (128, 128, 16)\n",
    "    x = tf.keras.layers.Conv2DTranspose(16, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Upsample to (256, 256, 3)\n",
    "    outputs = tf.keras.layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh', use_bias=False)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs,name='Decoder')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_layer = VectorQuantizer(num_embeddings, embedding_dim, name=\"vector_quantizer\")\n",
    "encoder = resnet_encoder(input_shape=(256, 256, 3), num_filters=64, latent_dim=embedding_dim)\n",
    "decoder = dcgenerator(encoder_output_shape)\n",
    "\n",
    "inputs = keras.Input(shape=(256, 256, 3))\n",
    "encoder_outputs = encoder(inputs)\n",
    "quantized_latents = vq_layer(encoder_outputs)\n",
    "reconstructions = decoder(quantized_latents)\n",
    "model = keras.Model(inputs, reconstructions, name=\"vq_vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vq_vae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " Encoder (Functional)        (None, 8, 8, 32)          11206112  \n",
      "                                                                 \n",
      " vector_quantizer (VectorQua  (None, 8, 8, 32)         16384     \n",
      " ntizer)                                                         \n",
      "                                                                 \n",
      " Decoder (Functional)        (None, 256, 256, 3)       239296    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,461,792\n",
      "Trainable params: 11,454,400\n",
      "Non-trainable params: 7,392\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work-portable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
